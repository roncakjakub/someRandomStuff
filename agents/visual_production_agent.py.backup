"""
Visual Production Agent V2 - Phase 3
Generates animated video content using AI-selected tools per scene.
Supports multiple video generation tools based on content type.
"""
from typing import Dict, Any, List, Optional
import logging
import os
from pathlib import Path

# Image generation tools
from tools import FluxSchnellTool, FluxDevTool, FluxProTool

# Video generation tools
from tools.luma_video import LumaVideoTool
from tools.runway_video import RunwayVideoTool
from tools.pika_video import PikaVideoTool
from tools.minimax_video import MinimaxVideoTool
from tools.wan_video import WanVideoTool

logger = logging.getLogger(__name__)


class VisualProductionAgent:
    """
    Visual Production Agent V2
    
    Generates animated video clips for each scene using:
    1. Image generation (Flux)
    2. Video animation (Minimax/Luma/Runway/Pika/Wan)
    
    Tool selection is driven by Workflow Router's scene_plans.
    """
    
    def __init__(self, quality: str = "dev"):
        """
        Initialize visual production agent.
        
        Args:
            quality: Image quality - "schnell" (fast), "dev" (balanced), "pro" (best)
        """
        self.name = "Visual Production Agent"
        self.logger = logging.getLogger(f"agents.{self.name}")
        self.quality = quality
        
        # Initialize image generation tools
        if quality == "pro":
            self.image_tool = FluxProTool()
        elif quality == "dev":
            self.image_tool = FluxDevTool()
        else:
            self.image_tool = FluxSchnellTool()
        
        # Initialize video generation tools
        self.video_tools = {
            "luma_ray": LumaVideoTool(),
            "runway_gen4": RunwayVideoTool(),
            "pika_v2": PikaVideoTool(),
            "minimax_hailuo": MinimaxVideoTool(),
            "wan_i2v": WanVideoTool(),
        }
        
        self.logger.info(f"Initialized with image quality: {quality}")
        self.logger.info(f"Available video tools: {list(self.video_tools.keys())}")
    
    def run(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        Main entry point called by workflow.
        
        Args:
            state: Workflow state containing:
                - prompts: Scenes from Creative Strategist
                - scene_plans: Tool selection from Workflow Router (optional)
                - run_output_dir: Output directory
        
        Returns:
            Updated state with generated video clips
        """
        prompts = state.get("prompts", {})
        scene_plans = state.get("scene_plans", [])
        output_dir = state.get("run_output_dir")
        
        result = self.generate_visuals(
            prompts=prompts,
            scene_plans=scene_plans,
            output_dir=output_dir
        )
        
        # Update state
        state.update(result)
        return state
    
    def generate_visuals(
        self,
        prompts: Dict[str, Any],
        scene_plans: List[Dict[str, Any]] = None,
        output_dir: str = None
    ) -> Dict[str, Any]:
        """
        Generate animated video clips for all scenes.
        
        Args:
            prompts: Prompts from Creative Strategist with scenes
            scene_plans: Optional tool selection from Workflow Router
            output_dir: Custom output directory
        
        Returns:
            Dictionary with:
                - scene_videos: List of video file paths
                - total_videos: Number of videos generated
                - total_cost: Total generation cost
                - total_time: Total generation time
        """
        self.logger.info("Starting visual content generation...")
        
        # Extract scenes
        scenes = prompts.get("scenes", [])
        
        if not scenes:
            self.logger.error("No scenes found in prompts")
            raise Exception("No scenes to generate")
        
        self.logger.info(f"Generating {len(scenes)} animated scenes...")
        
        # Create output directory
        if not output_dir:
            output_dir = "output/visuals"
        os.makedirs(output_dir, exist_ok=True)
        
        scene_videos = []
        total_cost = 0.0
        total_time = 0
        
        # Generate each scene
        for idx, scene in enumerate(scenes):
            scene_number = scene.get("number", idx + 1)
            scene_prompt = scene.get("prompt", "")
            scene_description = scene.get("description", "")
            content_type = scene.get("content_type", "object")
            
            if not scene_prompt:
                self.logger.warning(f"Scene {scene_number} has empty prompt, skipping")
                continue
            
            self.logger.info(f"Scene {scene_number}/{len(scenes)}: {scene_description}")
            self.logger.info(f"  Content type: {content_type}")
            
            try:
                # Get tool selection from scene_plans
                video_tool_name = self._get_video_tool_for_scene(
                    scene_number=scene_number,
                    content_type=content_type,
                    scene_plans=scene_plans
                )
                
                self.logger.info(f"  Selected video tool: {video_tool_name}")
                
                # Step 1: Generate static image
                self.logger.info(f"  Step 1/2: Generating image...")
                image_path = self._generate_image(
                    prompt=scene_prompt,
                    scene_number=scene_number,
                    output_dir=output_dir
                )
                
                # Step 2: Animate image to video
                if video_tool_name and video_tool_name != "none":
                    self.logger.info(f"  Step 2/2: Animating with {video_tool_name}...")
                    video_result = self._animate_image(
                        image_path=image_path,
                        video_tool_name=video_tool_name,
                        scene_description=scene_description,
                        scene_number=scene_number,
                        output_dir=output_dir
                    )
                    
                    video_path = video_result["video_path"]
                    total_cost += video_result.get("cost", 0.0)
                    total_time += video_result.get("time", 0)
                else:
                    # No animation - convert static image to video
                    self.logger.info(f"  Step 2/2: Converting static image to video...")
                    video_path = self._static_to_video(
                        image_path=image_path,
                        duration=scene.get("duration", 2.0),
                        scene_number=scene_number,
                        output_dir=output_dir
                    )
                
                scene_videos.append(video_path)
                self.logger.info(f"  ✓ Scene {scene_number} complete: {video_path}")
                
            except Exception as e:
                self.logger.error(f"  ✗ Scene {scene_number} failed: {e}")
                # Try fallback
                try:
                    self.logger.info(f"  Attempting fallback...")
                    video_path = self._fallback_scene_generation(
                        scene_prompt=scene_prompt,
                        scene_number=scene_number,
                        duration=scene.get("duration", 2.0),
                        output_dir=output_dir
                    )
                    scene_videos.append(video_path)
                    self.logger.info(f"  ✓ Fallback successful: {video_path}")
                except Exception as fallback_error:
                    self.logger.error(f"  ✗ Fallback also failed: {fallback_error}")
                    # Skip this scene
                    continue
        
        self.logger.info(f"Visual production complete: {len(scene_videos)} videos generated")
        self.logger.info(f"Total cost: ${total_cost:.2f}")
        self.logger.info(f"Total time: {total_time}s")
        
        return {
            "scene_videos": scene_videos,
            "all_images": scene_videos,  # For backward compatibility
            "total_videos": len(scene_videos),
            "total_cost": total_cost,
            "total_time": total_time
        }
    
    def _get_video_tool_for_scene(
        self,
        scene_number: int,
        content_type: str,
        scene_plans: List[Dict[str, Any]] = None
    ) -> str:
        """
        Get the video tool to use for this scene.
        
        Args:
            scene_number: Scene number (1-indexed)
            content_type: Content type from Creative Strategist
            scene_plans: Optional tool selection from Workflow Router
        
        Returns:
            Video tool name (e.g., "minimax_hailuo")
        """
        # If we have scene_plans from router, use that
        if scene_plans:
            for plan in scene_plans:
                if plan.get("scene_number") == scene_number:
                    return plan.get("video_tool", "runway_gen4")
        
        # Otherwise, use content_type to decide
        tool_mapping = {
            "human_action": "minimax_hailuo",
            "human_portrait": "minimax_hailuo",
            "object": "luma_ray",
            "product": "runway_gen4",
            "text": "none",  # No animation for text
            "transition": "pika_v2",
            "abstract": "wan_i2v"
        }
        
        return tool_mapping.get(content_type, "runway_gen4")
    
    def _generate_image(
        self,
        prompt: str,
        scene_number: int,
        output_dir: str
    ) -> str:
        """
        Generate static image using Flux.
        
        Args:
            prompt: Image generation prompt
            scene_number: Scene number for filename
            output_dir: Output directory
        
        Returns:
            Path to generated image
        """
        result = self.image_tool.run({
            "prompt": prompt,
            "output_dir": output_dir,
            "filename": f"scene_{scene_number:02d}_image.png"
        })
        
        return result["image_path"]
    
    def _animate_image(
        self,
        image_path: str,
        video_tool_name: str,
        scene_description: str,
        scene_number: int,
        output_dir: str
    ) -> Dict[str, Any]:
        """
        Animate static image to video using selected tool.
        
        Args:
            image_path: Path to static image
            video_tool_name: Name of video tool to use
            scene_description: Description for motion prompt
            scene_number: Scene number for filename
            output_dir: Output directory
        
        Returns:
            Dictionary with video_path, cost, time
        """
        # Get the tool
        video_tool = self.video_tools.get(video_tool_name)
        
        if not video_tool:
            self.logger.warning(f"Video tool '{video_tool_name}' not found, using runway_gen4")
            video_tool = self.video_tools["runway_gen4"]
        
        # Run the tool
        result = video_tool.run({
            "image_path": image_path,
            "prompt": scene_description,
            "duration": 5,  # Standard 5 seconds
            "output_dir": output_dir,
            "filename": f"scene_{scene_number:02d}_video.mp4"
        })
        
        return result
    
    def _static_to_video(
        self,
        image_path: str,
        duration: float,
        scene_number: int,
        output_dir: str
    ) -> str:
        """
        Convert static image to video (no animation).
        
        Args:
            image_path: Path to static image
            duration: Video duration in seconds
            scene_number: Scene number for filename
            output_dir: Output directory
        
        Returns:
            Path to video file
        """
        import subprocess
        
        output_path = os.path.join(output_dir, f"scene_{scene_number:02d}_static.mp4")
        
        # Use FFMPEG to create video from static image
        cmd = [
            "ffmpeg", "-y",
            "-loop", "1",
            "-i", image_path,
            "-c:v", "libx264",
            "-t", str(duration),
            "-pix_fmt", "yuv420p",
            "-vf", "scale=1080:1920",  # 9:16 vertical
            output_path
        ]
        
        subprocess.run(cmd, check=True, capture_output=True)
        
        return output_path
    
    def _fallback_scene_generation(
        self,
        scene_prompt: str,
        scene_number: int,
        duration: float,
        output_dir: str
    ) -> str:
        """
        Fallback: Generate image and convert to static video.
        
        Args:
            scene_prompt: Image prompt
            scene_number: Scene number
            duration: Video duration
            output_dir: Output directory
        
        Returns:
            Path to video file
        """
        # Generate image
        image_path = self._generate_image(
            prompt=scene_prompt,
            scene_number=scene_number,
            output_dir=output_dir
        )
        
        # Convert to static video
        video_path = self._static_to_video(
            image_path=image_path,
            duration=duration,
            scene_number=scene_number,
            output_dir=output_dir
        )
        
        return video_path


# Export
__all__ = ["VisualProductionAgent"]
